{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Sentence Encoder Baseline for XNLI task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will walk you through the process of reproducing the Universal Sentence Encoder baseline for XNLI task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Required Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the needed python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "import tensorflow_text\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pandas, we can load and inspect the training, validation, and testing datasets as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../../data/xnli/arabic_train.tsv\", sep=\"\\t\")\n",
    "df_test = pd.read_csv(\"../../data/xnli/arabic_dev.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we list the 5 first entries in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairID</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>حسنا ، لم أكن أفكر حتى حول ذلك ، لكن كنت محبطا...</td>\n",
       "      <td>لم أتحدث معه مرة أخرى.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>حسنا ، لم أكن أفكر حتى حول ذلك ، لكن كنت محبطا...</td>\n",
       "      <td>كنت مستاء جدا لدرجة أنني بدأت بالحديث معه مرة ...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>حسنا ، لم أكن أفكر حتى حول ذلك ، لكن كنت محبطا...</td>\n",
       "      <td>دار بيننا حديث رائع.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>واعتقدت أن ذلك شرف لي ، ولا يزال ، ولايزال ، ك...</td>\n",
       "      <td>لم أكن على علم بأنني لم أكن الشخص الوحيد الذي ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>واعتقدت أن ذلك شرف لي ، ولا يزال ، ولايزال ، ك...</td>\n",
       "      <td>كان لدي إنطباع أنني كنت الشخص الوحيد الذي لديه...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pairID                                          sentence1  \\\n",
       "0       4  حسنا ، لم أكن أفكر حتى حول ذلك ، لكن كنت محبطا...   \n",
       "1       5  حسنا ، لم أكن أفكر حتى حول ذلك ، لكن كنت محبطا...   \n",
       "2       6  حسنا ، لم أكن أفكر حتى حول ذلك ، لكن كنت محبطا...   \n",
       "3       7  واعتقدت أن ذلك شرف لي ، ولا يزال ، ولايزال ، ك...   \n",
       "4       8  واعتقدت أن ذلك شرف لي ، ولا يزال ، ولايزال ، ك...   \n",
       "\n",
       "                                           sentence2     gold_label  \n",
       "0                             لم أتحدث معه مرة أخرى.  contradiction  \n",
       "1  كنت مستاء جدا لدرجة أنني بدأت بالحديث معه مرة ...     entailment  \n",
       "2                               دار بيننا حديث رائع.        neutral  \n",
       "3  لم أكن على علم بأنني لم أكن الشخص الوحيد الذي ...        neutral  \n",
       "4  كان لدي إنطباع أنني كنت الشخص الوحيد الذي لديه...     entailment  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And last but not least, the first 5 entries in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairID</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>وقال، ماما، لقد عدت للمنزل.</td>\n",
       "      <td>اتصل بأمه حالما أوصلته حافلة المدرسية.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>وقال، ماما، لقد عدت للمنزل.</td>\n",
       "      <td>لم ينطق ببنت شفة.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>وقال، ماما، لقد عدت للمنزل.</td>\n",
       "      <td>أخبر أمه أنه قد عاد للمنزل.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>لم أعرف من أجل ماذا أنا ذاهب أو أي شىْ ، لذلك ...</td>\n",
       "      <td>لم أذهب إلى واشنطن من قبل، لذا عندما تم تكليفي...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>لم أعرف من أجل ماذا أنا ذاهب أو أي شىْ ، لذلك ...</td>\n",
       "      <td>لقد عرفت بالضبط ما الذي احتجت أن أفعله عندما م...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pairID                                          sentence1  \\\n",
       "0       1                        وقال، ماما، لقد عدت للمنزل.   \n",
       "1       2                        وقال، ماما، لقد عدت للمنزل.   \n",
       "2       3                        وقال، ماما، لقد عدت للمنزل.   \n",
       "3      16  لم أعرف من أجل ماذا أنا ذاهب أو أي شىْ ، لذلك ...   \n",
       "4      17  لم أعرف من أجل ماذا أنا ذاهب أو أي شىْ ، لذلك ...   \n",
       "\n",
       "                                           sentence2     gold_label  \n",
       "0             اتصل بأمه حالما أوصلته حافلة المدرسية.        neutral  \n",
       "1                                  لم ينطق ببنت شفة.  contradiction  \n",
       "2                        أخبر أمه أنه قد عاد للمنزل.     entailment  \n",
       "3  لم أذهب إلى واشنطن من قبل، لذا عندما تم تكليفي...        neutral  \n",
       "4  لقد عرفت بالضبط ما الذي احتجت أن أفعله عندما م...  contradiction  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by setting the randomisation seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load the Universal Sentence Encoder (WARNING: This will download and cache a huge model of around 1 GB in size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the input and output to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1_input = keras.Input(shape=512, name='sentence1')\n",
    "sentence2_input = keras.Input(shape=512, name='sentence2')\n",
    "label = keras.Input(shape=(1,), name='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is followed by defining the structure of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_1 = tf.abs(sentence1_input - sentence2_input)\n",
    "feat_2 = sentence1_input*sentence2_input\n",
    "features = tf.concat([sentence1_input, sentence2_input, feat_1, feat_2], 1)\n",
    "logits = keras.layers.Dense(512*4, activation=tf.nn.tanh)(features)\n",
    "logits = keras.layers.Dense(512*4, activation=tf.nn.tanh)(tf.concat([logits, features],1))\n",
    "logits = keras.layers.Dense(512*4, activation=tf.nn.tanh)(tf.concat([logits, features],1))\n",
    "logits = keras.layers.Dense(3, activation=tf.nn.softmax)(tf.concat([logits, features],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we construct and compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=[sentence1_input, sentence2_input], outputs=logits)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we perpare the inputs and outputs to be fed to the model during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = embed(df_train[\"sentence1\"])\n",
    "X2_train = embed(df_train[\"sentence2\"])\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train[\"gold_label\"])\n",
    "Y_train = le.transform(df_train[\"gold_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we fit the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "157/157 [==============================] - 14s 85ms/step - loss: 1.2351 - accuracy: 0.4275\n",
      "Epoch 2/5\n",
      "157/157 [==============================] - 13s 81ms/step - loss: 0.9382 - accuracy: 0.5648\n",
      "Epoch 3/5\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 0.9140 - accuracy: 0.5912\n",
      "Epoch 4/5\n",
      "157/157 [==============================] - 12s 75ms/step - loss: 0.8820 - accuracy: 0.6007\n",
      "Epoch 5/5\n",
      "157/157 [==============================] - 12s 75ms/step - loss: 0.8462 - accuracy: 0.6353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4ba06c4070>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X1_train, X2_train],\n",
    "          Y_train,\n",
    "          epochs=5,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we prepare the features for the test set as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test = embed(df_test[\"sentence1\"])\n",
    "X2_test = embed(df_test[\"sentence2\"])\n",
    "Y_test = le.transform(df_test[\"gold_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we prepare the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = np.argmax(model.predict([X1_test, X2_test]),1)\n",
    "df_test_sub = pd.DataFrame(data=le.inverse_transform(predictions_test), columns=[\"prediction\"], index=df_test[\"pairID\"])\n",
    "df_test_sub.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we save the prediction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"predictions\"):\n",
    "    os.mkdir(\"predictions\")\n",
    "df_test_sub.to_csv(\"./predictions/xnli.tsv\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we perpare the features for each testset instance as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic_data = pd.read_csv(\"../../private_datasets/diagnostic.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_dia = embed(diagnostic_data[\"sentence1\"].tolist())\n",
    "X2_dia = embed(diagnostic_data[\"sentence2\"].tolist())\n",
    "Y_dia = le.transform(diagnostic_data[\"gold_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we predict the labels for each and evaluate the f1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(model.predict([X1_dia, X2_dia]),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perpare the predictions as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dia = pd.DataFrame(data=le.inverse_transform(predictions), columns=[\"prediction\"], index=diagnostic_data[\"pairID\"])\n",
    "df_dia.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final step, we save the predictions as required by the competition guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dia.to_csv(\"./predictions/diagnostic.tsv\", index=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
