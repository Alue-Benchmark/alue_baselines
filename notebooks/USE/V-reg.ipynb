{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Sentence Encoder Baseline for V-reg Task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will walk you through the process of reproducing the Universal Sentence Encoder baseline for the V-reg task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Required Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the needed python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "import tensorflow_text\n",
    "from tensorflow import keras\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pandas, we can load and inspect the training, validation, and testing datasets as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../../data/affect-in-tweets/V-reg/2018-Valence-reg-Ar-train.txt\", sep=\"\\t\")\n",
    "df_dev = pd.read_csv(\"../../data/affect-in-tweets/V-reg/2018-Valence-reg-Ar-dev.txt\", sep=\"\\t\")\n",
    "df_test = pd.read_csv(\"../../private_datasets/vreg/vreg_no_labels_v1.0.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we list the 5 first entries in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Intensity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-Ar-01961</td>\n",
       "      <td>Ø¥Ù„Ù‰Ù° Ù…ØªÙ‰Ù° Ø§Ù„Ø£Ù„Ù… ÙŠØºÙ„Ø¨ Ø¹Ù„Ù‰ Ø§Ù„ÙØ±Ø­</td>\n",
       "      <td>valence</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-Ar-03289</td>\n",
       "      <td>@Al3mriRami @Holyliviuss ÙƒÙ„ Ù…Ø§ÙÙŠ Ø§Ù„Ø£Ù…Ø± Ø£Ù†ÙŠ ØºØ§Ø¶...</td>\n",
       "      <td>valence</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-Ar-04349</td>\n",
       "      <td>ÙŠØ­Ø°Ø±ÙƒÙ… ÙˆÙŠØ®ÙˆÙÙƒÙ… Ù…Ù† Ù†ÙØ³Ù‡ Ø§Ø°Ø§ Ø§Ø±ØªÙƒØ¨ØªÙ… Ø°Ù†Ø¨ Ø§Ùˆ Ù…Ø¹ØµÙŠ...</td>\n",
       "      <td>valence</td>\n",
       "      <td>0.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-Ar-03640</td>\n",
       "      <td>ğŸ’ ğŸ’ ØµØ¨Ø§Ø­ÙƒÙ… Ø³Ø¹Ø§Ø¯Ø© ÙÙŠ Ø§Ù„ÙŠÙˆÙ… Ø§Ù„Ù…Ø¨Ø§Ø±Ùƒ ØªÙ‚Ø¨Ù„ Ø§Ù„Ù„Ù‡ ØµÙŠ...</td>\n",
       "      <td>valence</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-Ar-01176</td>\n",
       "      <td>@sjalmulla Ø´ÙØªÙ‡ Ù‚Ø¨Ù„ Ø§Ø³Ø¨ÙˆØ¹ ÙˆÙ…ØªØ´ÙˆÙ‚Ù‡ Ø¹Ù„ÙŠÙ‡ ÙˆØ§ÙŠØ¯ Ø§Ù„...</td>\n",
       "      <td>valence</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                              Tweet  \\\n",
       "0  2018-Ar-01961                     Ø¥Ù„Ù‰Ù° Ù…ØªÙ‰Ù° Ø§Ù„Ø£Ù„Ù… ÙŠØºÙ„Ø¨ Ø¹Ù„Ù‰ Ø§Ù„ÙØ±Ø­   \n",
       "1  2018-Ar-03289  @Al3mriRami @Holyliviuss ÙƒÙ„ Ù…Ø§ÙÙŠ Ø§Ù„Ø£Ù…Ø± Ø£Ù†ÙŠ ØºØ§Ø¶...   \n",
       "2  2018-Ar-04349  ÙŠØ­Ø°Ø±ÙƒÙ… ÙˆÙŠØ®ÙˆÙÙƒÙ… Ù…Ù† Ù†ÙØ³Ù‡ Ø§Ø°Ø§ Ø§Ø±ØªÙƒØ¨ØªÙ… Ø°Ù†Ø¨ Ø§Ùˆ Ù…Ø¹ØµÙŠ...   \n",
       "3  2018-Ar-03640  ğŸ’ ğŸ’ ØµØ¨Ø§Ø­ÙƒÙ… Ø³Ø¹Ø§Ø¯Ø© ÙÙŠ Ø§Ù„ÙŠÙˆÙ… Ø§Ù„Ù…Ø¨Ø§Ø±Ùƒ ØªÙ‚Ø¨Ù„ Ø§Ù„Ù„Ù‡ ØµÙŠ...   \n",
       "4  2018-Ar-01176  @sjalmulla Ø´ÙØªÙ‡ Ù‚Ø¨Ù„ Ø§Ø³Ø¨ÙˆØ¹ ÙˆÙ…ØªØ´ÙˆÙ‚Ù‡ Ø¹Ù„ÙŠÙ‡ ÙˆØ§ÙŠØ¯ Ø§Ù„...   \n",
       "\n",
       "  Affect Dimension  Intensity Score  \n",
       "0          valence            0.097  \n",
       "1          valence            0.219  \n",
       "2          valence            0.313  \n",
       "3          valence            0.828  \n",
       "4          valence            0.719  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the 5 first entries in the development data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Intensity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-Ar-00297</td>\n",
       "      <td>Ù„Ø¤ÙŠ Ø¹Ø±ÙÙƒ Ù…Ù† Ø²Ù…Ø§Ø§Ù† Ø·ÙŠØ¨ ÙˆÙ…Ø­ØªØ±Ù… ÙˆØ¬Ø¯Ø¹ ÙˆÙ…Ø­Ø¨ÙˆØ¨ Ø±Ø¨Ù†Ø§ ...</td>\n",
       "      <td>valence</td>\n",
       "      <td>0.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-Ar-03228</td>\n",
       "      <td>Ù…Ø¯Ù…Ù† Ø§Ù„Ø¹Ø²Ù„Ø© ÙŠØ®Ø§Ù Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù… Ø§Ù„Ø²Ø§Ø¦Ø¯ ÙŠØªÙˆØªØ± Ù„Ø§ ÙŠØ­Ø³Ù†...</td>\n",
       "      <td>valence</td>\n",
       "      <td>0.328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-Ar-00857</td>\n",
       "      <td>ØªØ°ÙƒØ± Ø£Ù† Ø¨Ø¹Ø¯ Ø§Ù„Ø´Ù‚Ø§Ø¡ Ø³Ø¹Ø§Ø¯Ø© ÙˆØ¨Ø¹Ø¯ Ø¯Ù…ÙˆØ¹Ùƒ #Ø¥Ø¨ØªØ³Ø§Ù…Ø©</td>\n",
       "      <td>valence</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-Ar-02764</td>\n",
       "      <td>Ù…Ø§Ù ÙˆØ§Ø­Ø¯ Ù…ØªØ²ÙˆØ¬ Ø§Ø³Ø£Ù„Ù‡ Ø¹Ù† Ø§Ù„Ø²ÙˆØ§Ø¬ Ø§Ù„Ø§ ÙŠØ³Ø¨ ÙˆÙŠÙ„Ø¹Ù† Ùˆ...</td>\n",
       "      <td>valence</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-Ar-00582</td>\n",
       "      <td>Ù¢Ù¥ Ù„Ù„Ø§Ø³Ù Ù…Ø§ Ø¨Ø¹Ø±ÙÙƒ Ø¨Ø³ Ø¨Ø§ÙŠÙ† Ø§Ù†Ùƒ Ø­Ø¯ Ù…Ù†ÙŠØ­ ÙˆØ¯Ù…Ùƒ Ø®ÙÙŠ...</td>\n",
       "      <td>valence</td>\n",
       "      <td>0.547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                              Tweet  \\\n",
       "0  2018-Ar-00297  Ù„Ø¤ÙŠ Ø¹Ø±ÙÙƒ Ù…Ù† Ø²Ù…Ø§Ø§Ù† Ø·ÙŠØ¨ ÙˆÙ…Ø­ØªØ±Ù… ÙˆØ¬Ø¯Ø¹ ÙˆÙ…Ø­Ø¨ÙˆØ¨ Ø±Ø¨Ù†Ø§ ...   \n",
       "1  2018-Ar-03228  Ù…Ø¯Ù…Ù† Ø§Ù„Ø¹Ø²Ù„Ø© ÙŠØ®Ø§Ù Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù… Ø§Ù„Ø²Ø§Ø¦Ø¯ ÙŠØªÙˆØªØ± Ù„Ø§ ÙŠØ­Ø³Ù†...   \n",
       "2  2018-Ar-00857       ØªØ°ÙƒØ± Ø£Ù† Ø¨Ø¹Ø¯ Ø§Ù„Ø´Ù‚Ø§Ø¡ Ø³Ø¹Ø§Ø¯Ø© ÙˆØ¨Ø¹Ø¯ Ø¯Ù…ÙˆØ¹Ùƒ #Ø¥Ø¨ØªØ³Ø§Ù…Ø©   \n",
       "3  2018-Ar-02764  Ù…Ø§Ù ÙˆØ§Ø­Ø¯ Ù…ØªØ²ÙˆØ¬ Ø§Ø³Ø£Ù„Ù‡ Ø¹Ù† Ø§Ù„Ø²ÙˆØ§Ø¬ Ø§Ù„Ø§ ÙŠØ³Ø¨ ÙˆÙŠÙ„Ø¹Ù† Ùˆ...   \n",
       "4  2018-Ar-00582  Ù¢Ù¥ Ù„Ù„Ø§Ø³Ù Ù…Ø§ Ø¨Ø¹Ø±ÙÙƒ Ø¨Ø³ Ø¨Ø§ÙŠÙ† Ø§Ù†Ùƒ Ø­Ø¯ Ù…Ù†ÙŠØ­ ÙˆØ¯Ù…Ùƒ Ø®ÙÙŠ...   \n",
       "\n",
       "  Affect Dimension  Intensity Score  \n",
       "0          valence            0.613  \n",
       "1          valence            0.328  \n",
       "2          valence            0.625  \n",
       "3          valence            0.422  \n",
       "4          valence            0.547  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And last but not least, the first 5 entries in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Intensity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID-923</td>\n",
       "      <td>Ù„Ù„Ø§Ø³Ù Ø§ØªÙ‰ Ø¹Ù„ÙŠÙ†Ø§ Ø²Ù…Ù† Ø§ØµØ¨Ø­ Ø¨Ø¹Ø¶ Ø§Ù„Ø¢Ø¨Ø§Ø¡ Ù„ÙŠØ³ Ø­Ø¶Ù†Ø§Ù‹ ...</td>\n",
       "      <td>valence</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID-280</td>\n",
       "      <td>Ø§ÙŠÙ‡ Ø§Ù„ÙØ±Øµ Ø§Ù„Ù„ÙŠ Ø¨ØªØ¶ÙŠØ¹ Ù…Ù† Ø§Ù„Ø¨Ø±Ø§Ø²ÙŠÙ„ Ø¯ÙŠ Ø­Ø±Ø§Ø§Ù… Ø¨Ø¬Ø¯</td>\n",
       "      <td>valence</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID-406</td>\n",
       "      <td>Ø¬Ø§Øª Ù„Ù‰ Ø±ÙŠØ§Ø¯Ø© Ø£Ø·ÙØ§Ù„ .. Ù Ø§Ù„Ø§Ø³Ø¨ÙˆØ¹ Ø§Ù„Ø³Ø§Ø¯Ø³</td>\n",
       "      <td>valence</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID-423</td>\n",
       "      <td>Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ Ø§Ù†Ù‡ Ù…Ø§ ÙÙŠ Ø®Ø§ØµÙŠÙ‡ Ø¨ØªØ¨ÙŠÙ† ÙƒÙ… Ù…Ø±Ù‡ Ø­Ø¶Ø±Øª Ø§Ù„...</td>\n",
       "      <td>valence</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID-965</td>\n",
       "      <td>Ø§Ø¨ Ù‡Ù…ÙŠ ÙˆÙ‡Ù… Ø¨ÙŠ Ø£Ø­Ø¨Ø§Ø¨ÙŠ   Ù‡Ù…Ù‡Ù… Ù…Ø§ Ø¨Ù‡Ù… ÙˆÙ‡Ù…ÙŠ Ù…Ø§ Ø¨ÙŠ ...</td>\n",
       "      <td>valence</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                              Tweet Affect Dimension  \\\n",
       "0  ID-923  Ù„Ù„Ø§Ø³Ù Ø§ØªÙ‰ Ø¹Ù„ÙŠÙ†Ø§ Ø²Ù…Ù† Ø§ØµØ¨Ø­ Ø¨Ø¹Ø¶ Ø§Ù„Ø¢Ø¨Ø§Ø¡ Ù„ÙŠØ³ Ø­Ø¶Ù†Ø§Ù‹ ...          valence   \n",
       "1  ID-280      Ø§ÙŠÙ‡ Ø§Ù„ÙØ±Øµ Ø§Ù„Ù„ÙŠ Ø¨ØªØ¶ÙŠØ¹ Ù…Ù† Ø§Ù„Ø¨Ø±Ø§Ø²ÙŠÙ„ Ø¯ÙŠ Ø­Ø±Ø§Ø§Ù… Ø¨Ø¬Ø¯          valence   \n",
       "2  ID-406             Ø¬Ø§Øª Ù„Ù‰ Ø±ÙŠØ§Ø¯Ø© Ø£Ø·ÙØ§Ù„ .. Ù Ø§Ù„Ø§Ø³Ø¨ÙˆØ¹ Ø§Ù„Ø³Ø§Ø¯Ø³          valence   \n",
       "3  ID-423  Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ Ø§Ù†Ù‡ Ù…Ø§ ÙÙŠ Ø®Ø§ØµÙŠÙ‡ Ø¨ØªØ¨ÙŠÙ† ÙƒÙ… Ù…Ø±Ù‡ Ø­Ø¶Ø±Øª Ø§Ù„...          valence   \n",
       "4  ID-965  Ø§Ø¨ Ù‡Ù…ÙŠ ÙˆÙ‡Ù… Ø¨ÙŠ Ø£Ø­Ø¨Ø§Ø¨ÙŠ   Ù‡Ù…Ù‡Ù… Ù…Ø§ Ø¨Ù‡Ù… ÙˆÙ‡Ù…ÙŠ Ù…Ø§ Ø¨ÙŠ ...          valence   \n",
       "\n",
       "  Intensity Score  \n",
       "0            NONE  \n",
       "1            NONE  \n",
       "2            NONE  \n",
       "3            NONE  \n",
       "4            NONE  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by setting the randomisation seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load the Universal Sentence Encoder (WARNING: This will download and cache a huge model of around 1 GB in size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the input and output to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = keras.Input(shape=512, name='sentence')\n",
    "label = keras.Input(shape=(1,), name='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is followed by defining the structure of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = keras.layers.Dense(512, activation=tf.nn.sigmoid)(sentence)\n",
    "logits = keras.layers.Dense(512, activation=tf.nn.sigmoid)(logits)\n",
    "logits = keras.layers.Dense(1, activation=tf.nn.sigmoid)(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we construct and compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(sentence, outputs=logits)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we perpare the inputs and outputs to be fed to the model during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = embed(df_train[\"Tweet\"])\n",
    "Y_train = df_train[\"Intensity Score\"]\n",
    "X_dev = embed(df_dev[\"Tweet\"])\n",
    "Y_dev = df_dev[\"Intensity Score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we fit the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 2s 34ms/step - loss: 0.0818 - mae: 0.2390 - val_loss: 0.0691 - val_mae: 0.2257\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0544 - mae: 0.1990 - val_loss: 0.0361 - val_mae: 0.1574\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0510 - mae: 0.1875 - val_loss: 0.0509 - val_mae: 0.1920\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.0424 - mae: 0.1701 - val_loss: 0.0660 - val_mae: 0.2209\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0402 - mae: 0.1620 - val_loss: 0.0289 - val_mae: 0.1294\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0282 - mae: 0.1346 - val_loss: 0.0312 - val_mae: 0.1439\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0278 - mae: 0.1317 - val_loss: 0.0251 - val_mae: 0.1266\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0259 - mae: 0.1282 - val_loss: 0.0252 - val_mae: 0.1261\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0242 - mae: 0.1230 - val_loss: 0.0246 - val_mae: 0.1246\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0226 - mae: 0.1195 - val_loss: 0.0331 - val_mae: 0.1450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9f9c8df4f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          validation_data = (X_dev, Y_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the Pearson correlation coefficient for the development set as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6589736134728249, 1.5493966539516294e-18)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(Y_dev, model.predict(X_dev).reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perpare the features for each testset instance as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = embed(df_test[\"Tweet\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we predict the labels for each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perpare the predictions as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame(data=predictions, columns=[\"prediction\"], index=df_test[\"ID\"])\n",
    "df_preds.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final step, we save the predictions as required by the competition guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"predictions\"):\n",
    "    os.mkdir(\"predictions\")\n",
    "df_preds.to_csv(\"./predictions/v_reg.tsv\", index=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
