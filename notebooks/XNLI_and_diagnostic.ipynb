{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMO/ARAVEC/FASTTEXT Baseline for XNLI task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will walk you through the process of reproducing the ELMO/ARAVEC/FASTTEXT baseline for XNLI task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Required Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the needed python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fasttext'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b632ec41cdbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatthews_corrcoef\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0membed_classer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/alue_baselines/notebooks/elmo_aravec_fasttext/embed_classer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0melmoformanylangs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEmbedder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fasttext'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from embed_classer import embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext\n",
      "  Using cached fasttext-0.9.2.tar.gz (68 kB)\n",
      "Requirement already satisfied: pybind11>=2.2 in /home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages (from fasttext) (2.6.2)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages (from fasttext) (56.0.0)\n",
      "Requirement already satisfied: numpy in /home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages (from fasttext) (1.19.5)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /home/cadmus/PycharmProjects/alue_baselines/env/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-x3gug0_3/fasttext_b937466207874c4aa691daac03d97b55/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-x3gug0_3/fasttext_b937466207874c4aa691daac03d97b55/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-wgn_tx7p\n",
      "       cwd: /tmp/pip-install-x3gug0_3/fasttext_b937466207874c4aa691daac03d97b55/\n",
      "  Complete output (40 lines):\n",
      "  /home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/setuptools/dist.py:642: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "    warnings.warn(\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.linux-x86_64-3.8\n",
      "  creating build/lib.linux-x86_64-3.8/fasttext\n",
      "  copying python/fasttext_module/fasttext/FastText.py -> build/lib.linux-x86_64-3.8/fasttext\n",
      "  copying python/fasttext_module/fasttext/__init__.py -> build/lib.linux-x86_64-3.8/fasttext\n",
      "  creating build/lib.linux-x86_64-3.8/fasttext/util\n",
      "  copying python/fasttext_module/fasttext/util/util.py -> build/lib.linux-x86_64-3.8/fasttext/util\n",
      "  copying python/fasttext_module/fasttext/util/__init__.py -> build/lib.linux-x86_64-3.8/fasttext/util\n",
      "  creating build/lib.linux-x86_64-3.8/fasttext/tests\n",
      "  copying python/fasttext_module/fasttext/tests/test_configurations.py -> build/lib.linux-x86_64-3.8/fasttext/tests\n",
      "  copying python/fasttext_module/fasttext/tests/test_script.py -> build/lib.linux-x86_64-3.8/fasttext/tests\n",
      "  copying python/fasttext_module/fasttext/tests/__init__.py -> build/lib.linux-x86_64-3.8/fasttext/tests\n",
      "  running build_ext\n",
      "  creating tmp\n",
      "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/home/cadmus/PycharmProjects/alue_baselines/env/include -I/usr/include/python3.8 -c /tmp/tmp0m9mls_b.cpp -o tmp/tmp0m9mls_b.o -std=c++14\n",
      "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/home/cadmus/PycharmProjects/alue_baselines/env/include -I/usr/include/python3.8 -c /tmp/tmp6_6p7j5r.cpp -o tmp/tmp6_6p7j5r.o -fvisibility=hidden\n",
      "  building 'fasttext_pybind' extension\n",
      "  creating build/temp.linux-x86_64-3.8\n",
      "  creating build/temp.linux-x86_64-3.8/python\n",
      "  creating build/temp.linux-x86_64-3.8/python/fasttext_module\n",
      "  creating build/temp.linux-x86_64-3.8/python/fasttext_module/fasttext\n",
      "  creating build/temp.linux-x86_64-3.8/python/fasttext_module/fasttext/pybind\n",
      "  creating build/temp.linux-x86_64-3.8/src\n",
      "  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/pybind11/include -I/home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/pybind11/include -Isrc -I/home/cadmus/PycharmProjects/alue_baselines/env/include -I/usr/include/python3.8 -c python/fasttext_module/fasttext/pybind/fasttext_pybind.cc -o build/temp.linux-x86_64-3.8/python/fasttext_module/fasttext/pybind/fasttext_pybind.o -DVERSION_INFO=\"0.9.2\" -std=c++14 -fvisibility=hidden\n",
      "  In file included from /home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/pybind11/include/pybind11/pytypes.h:12,\n",
      "                   from /home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/pybind11/include/pybind11/cast.h:13,\n",
      "                   from /home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/pybind11/include/pybind11/attr.h:13,\n",
      "                   from /home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/pybind11/include/pybind11/pybind11.h:45,\n",
      "                   from /home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/pybind11/include/pybind11/numpy.h:12,\n",
      "                   from python/fasttext_module/fasttext/pybind/fasttext_pybind.cc:13:\n",
      "  /home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/pybind11/include/pybind11/detail/common.h:124:10: fatal error: Python.h: No such file or directory\n",
      "    124 | #include <Python.h>\n",
      "        |          ^~~~~~~~~~\n",
      "  compilation terminated.\n",
      "  error: command 'x86_64-linux-gnu-gcc' failed with exit status 1\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for fasttext\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for fasttext\n",
      "Failed to build fasttext\n",
      "Installing collected packages: fasttext\n",
      "    Running setup.py install for fasttext ... \u001b[?25lerror\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /home/cadmus/PycharmProjects/alue_baselines/env/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-x3gug0_3/fasttext_b937466207874c4aa691daac03d97b55/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-x3gug0_3/fasttext_b937466207874c4aa691daac03d97b55/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-rdcu96w4/install-record.txt --single-version-externally-managed --compile --install-headers /home/cadmus/PycharmProjects/alue_baselines/env/include/site/python3.8/fasttext\n",
      "         cwd: /tmp/pip-install-x3gug0_3/fasttext_b937466207874c4aa691daac03d97b55/\n",
      "    Complete output (39 lines):\n",
      "    /home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/setuptools/dist.py:642: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "      warnings.warn(\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.linux-x86_64-3.8\n",
      "    creating build/lib.linux-x86_64-3.8/fasttext\n",
      "    copying python/fasttext_module/fasttext/FastText.py -> build/lib.linux-x86_64-3.8/fasttext\n",
      "    copying python/fasttext_module/fasttext/__init__.py -> build/lib.linux-x86_64-3.8/fasttext\n",
      "    creating build/lib.linux-x86_64-3.8/fasttext/util\n",
      "    copying python/fasttext_module/fasttext/util/util.py -> build/lib.linux-x86_64-3.8/fasttext/util\n",
      "    copying python/fasttext_module/fasttext/util/__init__.py -> build/lib.linux-x86_64-3.8/fasttext/util\n",
      "    creating build/lib.linux-x86_64-3.8/fasttext/tests\n",
      "    copying python/fasttext_module/fasttext/tests/test_configurations.py -> build/lib.linux-x86_64-3.8/fasttext/tests\n",
      "    copying python/fasttext_module/fasttext/tests/test_script.py -> build/lib.linux-x86_64-3.8/fasttext/tests\n",
      "    copying python/fasttext_module/fasttext/tests/__init__.py -> build/lib.linux-x86_64-3.8/fasttext/tests\n",
      "    running build_ext\n",
      "    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/home/cadmus/PycharmProjects/alue_baselines/env/include -I/usr/include/python3.8 -c /tmp/tmpmjew16er.cpp -o tmp/tmpmjew16er.o -std=c++14\n",
      "    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/home/cadmus/PycharmProjects/alue_baselines/env/include -I/usr/include/python3.8 -c /tmp/tmp0d5iseoa.cpp -o tmp/tmp0d5iseoa.o -fvisibility=hidden\n",
      "    building 'fasttext_pybind' extension\n",
      "    creating build/temp.linux-x86_64-3.8\n",
      "    creating build/temp.linux-x86_64-3.8/python\n",
      "    creating build/temp.linux-x86_64-3.8/python/fasttext_module\n",
      "    creating build/temp.linux-x86_64-3.8/python/fasttext_module/fasttext\n",
      "    creating build/temp.linux-x86_64-3.8/python/fasttext_module/fasttext/pybind\n",
      "    creating build/temp.linux-x86_64-3.8/src\n",
      "    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/pybind11/include -I/home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/pybind11/include -Isrc -I/home/cadmus/PycharmProjects/alue_baselines/env/include -I/usr/include/python3.8 -c python/fasttext_module/fasttext/pybind/fasttext_pybind.cc -o build/temp.linux-x86_64-3.8/python/fasttext_module/fasttext/pybind/fasttext_pybind.o -DVERSION_INFO=\"0.9.2\" -std=c++14 -fvisibility=hidden\n",
      "    In file included from /home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/pybind11/include/pybind11/pytypes.h:12,\n",
      "                     from /home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/pybind11/include/pybind11/cast.h:13,\n",
      "                     from /home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/pybind11/include/pybind11/attr.h:13,\n",
      "                     from /home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/pybind11/include/pybind11/pybind11.h:45,\n",
      "                     from /home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/pybind11/include/pybind11/numpy.h:12,\n",
      "                     from python/fasttext_module/fasttext/pybind/fasttext_pybind.cc:13:\n",
      "    /home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/pybind11/include/pybind11/detail/common.h:124:10: fatal error: Python.h: No such file or directory\n",
      "      124 | #include <Python.h>\n",
      "          |          ^~~~~~~~~~\n",
      "    compilation terminated.\n",
      "    error: command 'x86_64-linux-gnu-gcc' failed with exit status 1\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: /home/cadmus/PycharmProjects/alue_baselines/env/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-x3gug0_3/fasttext_b937466207874c4aa691daac03d97b55/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-x3gug0_3/fasttext_b937466207874c4aa691daac03d97b55/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-rdcu96w4/install-record.txt --single-version-externally-managed --compile --install-headers /home/cadmus/PycharmProjects/alue_baselines/env/include/site/python3.8/fasttext Check the logs for full command output.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pandas, we can load and inspect the training, validation, and testing datasets as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../../data/xnli/arabic_train.tsv\", sep=\"\\t\")\n",
    "df_test = pd.read_csv(\"../../data/xnli/arabic_dev.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we list the 5 first entries in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And last but not least, the first 5 entries in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by setting the randomisation seed and the maximum sentence length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(123)\n",
    "max_sentence_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"fasttext\"\n",
    "\n",
    "if model_type == \"aravec\":\n",
    "    model_path = '/code/haitham/use_multi_bench/elmo_aravec_fasttext/aravec/full_uni_sg_300_twitter.mdl'\n",
    "    size = 300\n",
    "elif model_type == \"fasttext\":\n",
    "    model_path = '/code/haitham/use_multi_bench/elmo_aravec_fasttext/fasttext/cc.ar.300.bin'\n",
    "    size = 300\n",
    "elif model_type == \"elmo\":\n",
    "    model_path= '/code/haitham/use_multi_bench/elmo_aravec_fasttext/arabic_elmo'\n",
    "    size = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load our model of choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = embed(model_type, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the input and output to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = keras.Input(shape=(max_sentence_len, size), name='q1')\n",
    "sentence2 = keras.Input(shape=(max_sentence_len, size), name='q2')\n",
    "label = keras.Input(shape=(1,), name='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is followed by defining the structure of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_1 = tf.abs(sentence1 - sentence2)\n",
    "feat_2 = sentence1*sentence2\n",
    "forward_layer = tf.keras.layers.LSTM(size)\n",
    "backward_layer = tf.keras.layers.LSTM(size, go_backwards=True)\n",
    "masking_layer = tf.keras.layers.Masking()\n",
    "rnn = tf.keras.layers.Bidirectional(forward_layer, backward_layer=backward_layer)\n",
    "sentence1_logits = rnn(sentence1)\n",
    "sentence2_logits = rnn(sentence2)\n",
    "feat_1 = tf.abs(sentence1_logits - sentence2_logits)\n",
    "feat_2 = sentence1_logits*sentence2_logits\n",
    "logits = keras.layers.Dense(size*2, activation=tf.nn.sigmoid)(tf.keras.layers.concatenate([sentence1_logits, sentence2_logits, feat_1, feat_2]))\n",
    "logits = keras.layers.Dense(3, activation=tf.nn.softmax)(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we construct and compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=[sentence1, sentence2], outputs=logits)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we perpare the inputs and outputs to be fed to the model during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = embedder.embed_batch(df_train[\"sentence1\"].tolist(), max_sentence_len)\n",
    "X2_train = embedder.embed_batch(df_train[\"sentence2\"].tolist(), max_sentence_len)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train[\"gold_label\"])\n",
    "Y_train = le.transform(df_train[\"gold_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we fit the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([X1_train, X2_train],\n",
    "          Y_train,\n",
    "          epochs=5,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we prepare the features for the test set as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test = embedder.embed_batch(df_test[\"sentence1\"].tolist(), max_sentence_len)\n",
    "X2_test = embedder.embed_batch(df_test[\"sentence2\"].tolist(), max_sentence_len)\n",
    "Y_test = le.transform(df_test[\"gold_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we prepare the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = np.argmax(model.predict([X1_test, X2_test]),1)\n",
    "df_test_sub = pd.DataFrame(data=le.inverse_transform(predictions_test), columns=[\"prediction\"], index=df_test[\"pairID\"])\n",
    "df_test_sub.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we save the prediction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./predictions/{}\".format(model_type)):\n",
    "    os.makedirs(\"./predictions/{}\".format(model_type), exist_ok=True)\n",
    "df_dia.to_csv(\"./predictions/{}/xnli.tsv\".format(model_type), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we prepare the diagnostic task predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic_data = pd.read_csv(\"../../private_datasets/diagnostic.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perpare the features for each testset instance as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_dia = embedder.embed_batch(diagnostic_data[\"sentence1\"].tolist(), max_sentence_len)\n",
    "X2_dia = embedder.embed_batch(diagnostic_data[\"sentence2\"].tolist(), max_sentence_len)\n",
    "Y_dia = le.transform(diagnostic_data[\"gold_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we predict the labels for each and evaluate the f1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(model.predict([X1_dia, X2_dia]),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perpare the predictions as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dia = pd.DataFrame(data=le.inverse_transform(predictions), columns=[\"prediction\"], index=diagnostic_data[\"pairID\"])\n",
    "df_dia.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final step, we save the predictions as required by the competition guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dia.to_csv(\"./predictions/{}/diagnostic.tsv\".format(model_type), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
