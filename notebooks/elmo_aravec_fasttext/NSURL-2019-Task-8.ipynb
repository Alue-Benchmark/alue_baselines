{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMO/ARAVEC/FASTTEXT Baseline for NSURL-2019 Shared Task 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will walk you through the process of reproducing the ELMO/ARAVEC/FASTTEXT baseline for the NSURL-2019 Shared Task 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Required Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the needed python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import f1_score\n",
    "import gensim\n",
    "import numpy as np\n",
    "import fasttext\n",
    "from embed_classer import embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pandas, we can load and inspect the training, validation, and testing datasets as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../../data/nsurl/q2q_similarity_workshop_v2.1.tsv\", sep=\"\\t\")\n",
    "df_test = pd.read_csv(\"../../private_datasets/q2q/q2q_no_labels_v1.0.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we list the 5 first entries in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ما هي الطرق الصحيحة للاعتناء بالحامل؟</td>\n",
       "      <td>كيف اهتم بطفلي؟</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ما هي وسائل الاتصالات الحديثة؟</td>\n",
       "      <td>ماذا نعني بوسائل الاتصال الحديثة؟</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ما طريقة تحضير محشي الكوسا ؟</td>\n",
       "      <td>من طرق تحضير محشي الكوسا؟</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ما طريقة تحضير حلى الطبقات؟</td>\n",
       "      <td>من طرق تحضير   طبقات الكيك؟</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>من الآيات  القرآنية عن الراعي والرعية ؟</td>\n",
       "      <td>ما هو تعريف الراعي والرعية ؟</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 question1                          question2  \\\n",
       "0    ما هي الطرق الصحيحة للاعتناء بالحامل؟                    كيف اهتم بطفلي؟   \n",
       "1           ما هي وسائل الاتصالات الحديثة؟  ماذا نعني بوسائل الاتصال الحديثة؟   \n",
       "2             ما طريقة تحضير محشي الكوسا ؟          من طرق تحضير محشي الكوسا؟   \n",
       "3              ما طريقة تحضير حلى الطبقات؟        من طرق تحضير   طبقات الكيك؟   \n",
       "4  من الآيات  القرآنية عن الراعي والرعية ؟       ما هو تعريف الراعي والرعية ؟   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      1  \n",
       "2      1  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And last but not least, the first 5 entries in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionPairID</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>كم عدد حروف الفاتحة؟</td>\n",
       "      <td>كيف تكون فقيهاً؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>هل حلال أكل الضبع؟</td>\n",
       "      <td>هل أكل الضبع حلال أم حرام؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>كم عدد الركعات في كل صلاة؟</td>\n",
       "      <td>كم عدد ركعات الصلوات المفروضة؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>كيف أؤمن بالله؟</td>\n",
       "      <td>كيف أكون مؤمناً؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>لماذا سميت حواء بهذا الاسم؟</td>\n",
       "      <td>كيف عذب الله قوم ثمود؟</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuestionPairID                    question1                       question2\n",
       "0               1         كم عدد حروف الفاتحة؟                كيف تكون فقيهاً؟\n",
       "1               2           هل حلال أكل الضبع؟      هل أكل الضبع حلال أم حرام؟\n",
       "2               3   كم عدد الركعات في كل صلاة؟  كم عدد ركعات الصلوات المفروضة؟\n",
       "3               4              كيف أؤمن بالله؟                كيف أكون مؤمناً؟\n",
       "4               5  لماذا سميت حواء بهذا الاسم؟          كيف عذب الله قوم ثمود؟"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by setting the randomisation seed and the maximum sentence length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(123)\n",
    "max_sentence_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"fasttext\"\n",
    "\n",
    "if model_type == \"aravec\":\n",
    "    model_path = '../pretrained/full_uni_sg_300_twitter.mdl'\n",
    "    size = 300\n",
    "elif model_type == \"fasttext\":\n",
    "    model_path = '../pretrained/cc.ar.300.bin'\n",
    "    size = 300\n",
    "elif model_type == \"elmo\":\n",
    "    model_path= '../pretrained'\n",
    "    size = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load our model of choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "embedder = embed(model_type, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the input and output to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_input = keras.Input(shape=(max_sentence_len, size), name='q1')\n",
    "q2_input = keras.Input(shape=(max_sentence_len, size), name='q2')\n",
    "label = keras.Input(shape=(1,), name='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is followed by defining the structure of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_1 = tf.abs(q1_input - q2_input)\n",
    "feat_2 = q1_input*q2_input\n",
    "forward_layer = tf.keras.layers.LSTM(size)\n",
    "backward_layer = tf.keras.layers.LSTM(size, go_backwards=True)\n",
    "masking_layer = tf.keras.layers.Masking()\n",
    "rnn = tf.keras.layers.Bidirectional(forward_layer, backward_layer=backward_layer)\n",
    "q1_logits = rnn(q1_input)\n",
    "q2_logits = rnn(q2_input)\n",
    "feat_1 = tf.abs(q1_logits - q2_logits)\n",
    "feat_2 = q1_logits*q2_logits\n",
    "logits = keras.layers.Dense(size*2, activation=tf.nn.sigmoid)(tf.keras.layers.concatenate([q1_logits, q2_logits, feat_1, feat_2]))\n",
    "logits = keras.layers.Dense(1, activation=tf.nn.sigmoid)(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we construct and compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=[q1_input, q2_input], outputs=logits)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we perpare the inputs and outputs to be fed to the model during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = df_train[\"question1\"].tolist()\n",
    "q2 = df_train[\"question2\"].tolist()\n",
    "X1_train = embedder.embed_batch(q1, max_sentence_len)\n",
    "X2_train = embedder.embed_batch(q2, max_sentence_len)\n",
    "Y_train = df_train[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we fit the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 85s 215ms/step - loss: 0.6402 - accuracy: 0.6303\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 76s 203ms/step - loss: 0.6059 - accuracy: 0.6431\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 76s 203ms/step - loss: 0.4639 - accuracy: 0.7691\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 77s 204ms/step - loss: 0.3812 - accuracy: 0.8221\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 76s 203ms/step - loss: 0.3279 - accuracy: 0.8475\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 76s 203ms/step - loss: 0.3529 - accuracy: 0.8336\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 72s 192ms/step - loss: 0.2581 - accuracy: 0.8844\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 74s 198ms/step - loss: 0.2322 - accuracy: 0.9018\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 73s 195ms/step - loss: 0.1985 - accuracy: 0.9201\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 72s 192ms/step - loss: 0.1725 - accuracy: 0.9308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9178a41198>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X1_train, X2_train],\n",
    "          Y_train,\n",
    "          epochs=10,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perpare the features for each testset instance as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_test = embedder.embed_batch(df_test[\"question1\"].tolist(), max_sentence_len)\n",
    "x2_test = embedder.embed_batch(df_test[\"question2\"].tolist(), max_sentence_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we predict the labels for each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (model.predict([x1_test, x2_test])>0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perpare the predictions as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame(data=predictions, columns=[\"prediction\"], index=df_test[\"QuestionPairID\"])\n",
    "df_preds.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final step, we save the predictions as required by the competition guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./predictions/{}\".format(model_type)):\n",
    "    os.makedirs(\"./predictions/{}\".format(model_type), exist_ok=True)\n",
    "df_preds.to_csv(\"./predictions/{}/q2q.tsv\".format(model_type), index=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
