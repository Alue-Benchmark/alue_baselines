{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMO/ARAVEC/FASTTEXT Baseline for XNLI and Diagnostic tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will walk you through the process of reproducing the ELMO/ARAVEC/FASTTEXT baseline for XNLI task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Required Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the needed python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from embed_classer import embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pandas, we can load and inspect the training, validation, and testing datasets as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../../data/xnli/arabic_train.tsv\", sep=\"\\t\")\n",
    "df_test = pd.read_csv(\"../../data/xnli/arabic_dev.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we list the 5 first entries in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairID</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>حسنا ، لم أكن أفكر حتى حول ذلك ، لكن كنت محبطا...</td>\n",
       "      <td>لم أتحدث معه مرة أخرى.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>حسنا ، لم أكن أفكر حتى حول ذلك ، لكن كنت محبطا...</td>\n",
       "      <td>كنت مستاء جدا لدرجة أنني بدأت بالحديث معه مرة ...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>حسنا ، لم أكن أفكر حتى حول ذلك ، لكن كنت محبطا...</td>\n",
       "      <td>دار بيننا حديث رائع.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>واعتقدت أن ذلك شرف لي ، ولا يزال ، ولايزال ، ك...</td>\n",
       "      <td>لم أكن على علم بأنني لم أكن الشخص الوحيد الذي ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>واعتقدت أن ذلك شرف لي ، ولا يزال ، ولايزال ، ك...</td>\n",
       "      <td>كان لدي إنطباع أنني كنت الشخص الوحيد الذي لديه...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pairID                                          sentence1  \\\n",
       "0       4  حسنا ، لم أكن أفكر حتى حول ذلك ، لكن كنت محبطا...   \n",
       "1       5  حسنا ، لم أكن أفكر حتى حول ذلك ، لكن كنت محبطا...   \n",
       "2       6  حسنا ، لم أكن أفكر حتى حول ذلك ، لكن كنت محبطا...   \n",
       "3       7  واعتقدت أن ذلك شرف لي ، ولا يزال ، ولايزال ، ك...   \n",
       "4       8  واعتقدت أن ذلك شرف لي ، ولا يزال ، ولايزال ، ك...   \n",
       "\n",
       "                                           sentence2     gold_label  \n",
       "0                             لم أتحدث معه مرة أخرى.  contradiction  \n",
       "1  كنت مستاء جدا لدرجة أنني بدأت بالحديث معه مرة ...     entailment  \n",
       "2                               دار بيننا حديث رائع.        neutral  \n",
       "3  لم أكن على علم بأنني لم أكن الشخص الوحيد الذي ...        neutral  \n",
       "4  كان لدي إنطباع أنني كنت الشخص الوحيد الذي لديه...     entailment  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And last but not least, the first 5 entries in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairID</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>وقال، ماما، لقد عدت للمنزل.</td>\n",
       "      <td>اتصل بأمه حالما أوصلته حافلة المدرسية.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>وقال، ماما، لقد عدت للمنزل.</td>\n",
       "      <td>لم ينطق ببنت شفة.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>وقال، ماما، لقد عدت للمنزل.</td>\n",
       "      <td>أخبر أمه أنه قد عاد للمنزل.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>لم أعرف من أجل ماذا أنا ذاهب أو أي شىْ ، لذلك ...</td>\n",
       "      <td>لم أذهب إلى واشنطن من قبل، لذا عندما تم تكليفي...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>لم أعرف من أجل ماذا أنا ذاهب أو أي شىْ ، لذلك ...</td>\n",
       "      <td>لقد عرفت بالضبط ما الذي احتجت أن أفعله عندما م...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pairID                                          sentence1  \\\n",
       "0       1                        وقال، ماما، لقد عدت للمنزل.   \n",
       "1       2                        وقال، ماما، لقد عدت للمنزل.   \n",
       "2       3                        وقال، ماما، لقد عدت للمنزل.   \n",
       "3      16  لم أعرف من أجل ماذا أنا ذاهب أو أي شىْ ، لذلك ...   \n",
       "4      17  لم أعرف من أجل ماذا أنا ذاهب أو أي شىْ ، لذلك ...   \n",
       "\n",
       "                                           sentence2     gold_label  \n",
       "0             اتصل بأمه حالما أوصلته حافلة المدرسية.        neutral  \n",
       "1                                  لم ينطق ببنت شفة.  contradiction  \n",
       "2                        أخبر أمه أنه قد عاد للمنزل.     entailment  \n",
       "3  لم أذهب إلى واشنطن من قبل، لذا عندما تم تكليفي...        neutral  \n",
       "4  لقد عرفت بالضبط ما الذي احتجت أن أفعله عندما م...  contradiction  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by setting the randomisation seed and the maximum sentence length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(123)\n",
    "max_sentence_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"fasttext\"\n",
    "\n",
    "if model_type == \"aravec\":\n",
    "    model_path = '../pretrained/full_uni_sg_300_twitter.mdl'\n",
    "    size = 300\n",
    "elif model_type == \"fasttext\":\n",
    "    model_path = '../pretrained/cc.ar.300.bin'\n",
    "    size = 300\n",
    "elif model_type == \"elmo\":\n",
    "    model_path= '../pretrained'\n",
    "    size = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load our model of choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "embedder = embed(model_type, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the input and output to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = keras.Input(shape=(max_sentence_len, size), name='q1')\n",
    "sentence2 = keras.Input(shape=(max_sentence_len, size), name='q2')\n",
    "label = keras.Input(shape=(1,), name='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is followed by defining the structure of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_1 = tf.abs(sentence1 - sentence2)\n",
    "feat_2 = sentence1*sentence2\n",
    "forward_layer = tf.keras.layers.LSTM(size)\n",
    "backward_layer = tf.keras.layers.LSTM(size, go_backwards=True)\n",
    "masking_layer = tf.keras.layers.Masking()\n",
    "rnn = tf.keras.layers.Bidirectional(forward_layer, backward_layer=backward_layer)\n",
    "sentence1_logits = rnn(sentence1)\n",
    "sentence2_logits = rnn(sentence2)\n",
    "feat_1 = tf.abs(sentence1_logits - sentence2_logits)\n",
    "feat_2 = sentence1_logits*sentence2_logits\n",
    "logits = keras.layers.Dense(size*2, activation=tf.nn.sigmoid)(tf.keras.layers.concatenate([sentence1_logits, sentence2_logits, feat_1, feat_2]))\n",
    "logits = keras.layers.Dense(3, activation=tf.nn.softmax)(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we construct and compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=[sentence1, sentence2], outputs=logits)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we perpare the inputs and outputs to be fed to the model during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = embedder.embed_batch(df_train[\"sentence1\"].tolist(), max_sentence_len)\n",
    "X2_train = embedder.embed_batch(df_train[\"sentence2\"].tolist(), max_sentence_len)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train[\"gold_label\"])\n",
    "Y_train = le.transform(df_train[\"gold_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we fit the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "157/157 [==============================] - 19s 103ms/step - loss: 1.0870 - accuracy: 0.3929\n",
      "Epoch 2/5\n",
      "157/157 [==============================] - 16s 104ms/step - loss: 0.9894 - accuracy: 0.5003\n",
      "Epoch 3/5\n",
      "157/157 [==============================] - 16s 105ms/step - loss: 0.9398 - accuracy: 0.5356\n",
      "Epoch 4/5\n",
      "157/157 [==============================] - 17s 106ms/step - loss: 0.8902 - accuracy: 0.5814\n",
      "Epoch 5/5\n",
      "157/157 [==============================] - 17s 108ms/step - loss: 0.8232 - accuracy: 0.6245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f71047a7340>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X1_train, X2_train],\n",
    "          Y_train,\n",
    "          epochs=5,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XNLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we prepare the features for the test set as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test = embedder.embed_batch(df_test[\"sentence1\"].tolist(), max_sentence_len)\n",
    "X2_test = embedder.embed_batch(df_test[\"sentence2\"].tolist(), max_sentence_len)\n",
    "Y_test = le.transform(df_test[\"gold_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we prepare the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = np.argmax(model.predict([X1_test, X2_test]),1)\n",
    "df_test_sub = pd.DataFrame(data=le.inverse_transform(predictions_test), columns=[\"prediction\"], index=df_test[\"pairID\"])\n",
    "df_test_sub.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we save the prediction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./predictions/{}\".format(model_type)):\n",
    "    os.makedirs(\"./predictions/{}\".format(model_type), exist_ok=True)\n",
    "df_test_sub.to_csv(\"./predictions/{}/xnli.tsv\".format(model_type), index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we prepare the diagnostic task predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic_data = pd.read_csv(\"../../private_datasets/diagnostic.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perpare the features for each testset instance as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_dia = embedder.embed_batch(diagnostic_data[\"sentence1\"].tolist(), max_sentence_len)\n",
    "X2_dia = embedder.embed_batch(diagnostic_data[\"sentence2\"].tolist(), max_sentence_len)\n",
    "Y_dia = le.transform(diagnostic_data[\"gold_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we predict the labels for each and evaluate the f1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(model.predict([X1_dia, X2_dia]),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perpare the predictions as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dia = pd.DataFrame(data=le.inverse_transform(predictions), columns=[\"prediction\"], index=diagnostic_data[\"pairID\"])\n",
    "df_dia.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final step, we save the predictions as required by the competition guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dia.to_csv(\"./predictions/{}/diagnostic.tsv\".format(model_type), index=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
