{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMO/ARAVEC/FASTTEXT Baseline for V-reg Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will walk you through the process of reproducing the ELMO/ARAVEC/FASTTEXT baseline for the V-reg task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Required Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the needed python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from embed_classer import embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pandas, we can load and inspect the training, validation, and testing datasets as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../../data/affect-in-tweets/V-reg/2018-Valence-reg-Ar-train.txt\", sep=\"\\t\")\n",
    "df_dev = pd.read_csv(\"../../data/affect-in-tweets/V-reg/2018-Valence-reg-Ar-dev.txt\", sep=\"\\t\")\n",
    "df_test = pd.read_csv(\"../../private_datasets/vreg/vreg_no_labels_v1.0.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we list the 5 first entries in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Intensity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-Ar-01961</td>\n",
       "      <td>إلىٰ متىٰ الألم يغلب على الفرح</td>\n",
       "      <td>valence</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-Ar-03289</td>\n",
       "      <td>@Al3mriRami @Holyliviuss كل مافي الأمر أني غاض...</td>\n",
       "      <td>valence</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-Ar-04349</td>\n",
       "      <td>يحذركم ويخوفكم من نفسه اذا ارتكبتم ذنب او معصي...</td>\n",
       "      <td>valence</td>\n",
       "      <td>0.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-Ar-03640</td>\n",
       "      <td>💞 💞 صباحكم سعادة في اليوم المبارك تقبل الله صي...</td>\n",
       "      <td>valence</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-Ar-01176</td>\n",
       "      <td>@sjalmulla شفته قبل اسبوع ومتشوقه عليه وايد ال...</td>\n",
       "      <td>valence</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                              Tweet  \\\n",
       "0  2018-Ar-01961                     إلىٰ متىٰ الألم يغلب على الفرح   \n",
       "1  2018-Ar-03289  @Al3mriRami @Holyliviuss كل مافي الأمر أني غاض...   \n",
       "2  2018-Ar-04349  يحذركم ويخوفكم من نفسه اذا ارتكبتم ذنب او معصي...   \n",
       "3  2018-Ar-03640  💞 💞 صباحكم سعادة في اليوم المبارك تقبل الله صي...   \n",
       "4  2018-Ar-01176  @sjalmulla شفته قبل اسبوع ومتشوقه عليه وايد ال...   \n",
       "\n",
       "  Affect Dimension  Intensity Score  \n",
       "0          valence            0.097  \n",
       "1          valence            0.219  \n",
       "2          valence            0.313  \n",
       "3          valence            0.828  \n",
       "4          valence            0.719  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the 5 first entries in the development data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Intensity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-Ar-00297</td>\n",
       "      <td>لؤي عرفك من زماان طيب ومحترم وجدع ومحبوب ربنا ...</td>\n",
       "      <td>valence</td>\n",
       "      <td>0.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-Ar-03228</td>\n",
       "      <td>مدمن العزلة يخاف الاهتمام الزائد يتوتر لا يحسن...</td>\n",
       "      <td>valence</td>\n",
       "      <td>0.328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-Ar-00857</td>\n",
       "      <td>تذكر أن بعد الشقاء سعادة وبعد دموعك #إبتسامة</td>\n",
       "      <td>valence</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-Ar-02764</td>\n",
       "      <td>ماف واحد متزوج اسأله عن الزواج الا يسب ويلعن و...</td>\n",
       "      <td>valence</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-Ar-00582</td>\n",
       "      <td>٢٥ للاسف ما بعرفك بس باين انك حد منيح ودمك خفي...</td>\n",
       "      <td>valence</td>\n",
       "      <td>0.547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                              Tweet  \\\n",
       "0  2018-Ar-00297  لؤي عرفك من زماان طيب ومحترم وجدع ومحبوب ربنا ...   \n",
       "1  2018-Ar-03228  مدمن العزلة يخاف الاهتمام الزائد يتوتر لا يحسن...   \n",
       "2  2018-Ar-00857       تذكر أن بعد الشقاء سعادة وبعد دموعك #إبتسامة   \n",
       "3  2018-Ar-02764  ماف واحد متزوج اسأله عن الزواج الا يسب ويلعن و...   \n",
       "4  2018-Ar-00582  ٢٥ للاسف ما بعرفك بس باين انك حد منيح ودمك خفي...   \n",
       "\n",
       "  Affect Dimension  Intensity Score  \n",
       "0          valence            0.613  \n",
       "1          valence            0.328  \n",
       "2          valence            0.625  \n",
       "3          valence            0.422  \n",
       "4          valence            0.547  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And last but not least, the first 5 entries in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Intensity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID-923</td>\n",
       "      <td>للاسف اتى علينا زمن اصبح بعض الآباء ليس حضناً ...</td>\n",
       "      <td>valence</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID-280</td>\n",
       "      <td>ايه الفرص اللي بتضيع من البرازيل دي حراام بجد</td>\n",
       "      <td>valence</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID-406</td>\n",
       "      <td>جات لى ريادة أطفال .. ف الاسبوع السادس</td>\n",
       "      <td>valence</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID-423</td>\n",
       "      <td>الحمد لله انه ما في خاصيه بتبين كم مره حضرت ال...</td>\n",
       "      <td>valence</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID-965</td>\n",
       "      <td>اب همي وهم بي أحبابي   همهم ما بهم وهمي ما بي ...</td>\n",
       "      <td>valence</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                              Tweet Affect Dimension  \\\n",
       "0  ID-923  للاسف اتى علينا زمن اصبح بعض الآباء ليس حضناً ...          valence   \n",
       "1  ID-280      ايه الفرص اللي بتضيع من البرازيل دي حراام بجد          valence   \n",
       "2  ID-406             جات لى ريادة أطفال .. ف الاسبوع السادس          valence   \n",
       "3  ID-423  الحمد لله انه ما في خاصيه بتبين كم مره حضرت ال...          valence   \n",
       "4  ID-965  اب همي وهم بي أحبابي   همهم ما بهم وهمي ما بي ...          valence   \n",
       "\n",
       "  Intensity Score  \n",
       "0            NONE  \n",
       "1            NONE  \n",
       "2            NONE  \n",
       "3            NONE  \n",
       "4            NONE  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by setting the randomisation seed and the maximum sentence length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(123)\n",
    "max_sentence_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"aravec\"\n",
    "\n",
    "if model_type == \"aravec\":\n",
    "    model_path = '../pretrained/full_uni_sg_300_twitter.mdl'\n",
    "    size = 300\n",
    "elif model_type == \"fasttext\":\n",
    "    model_path = '../pretrained/cc.ar.300.bin'\n",
    "    size = 300\n",
    "elif model_type == \"elmo\":\n",
    "    model_path= '../pretrained'\n",
    "    size = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load our model of choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = embed(model_type, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the input and output to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = keras.Input(shape=(max_sentence_len, size), name='sentence')\n",
    "label = keras.Input(shape=(1,), name='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is followed by defining the structure of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_layer = tf.keras.layers.LSTM(size)\n",
    "backward_layer = tf.keras.layers.LSTM(size, go_backwards=True)\n",
    "masking_layer = tf.keras.layers.Masking()\n",
    "rnn = tf.keras.layers.Bidirectional(forward_layer, backward_layer=backward_layer)\n",
    "logits = rnn(sentence)\n",
    "logits = keras.layers.Dense(1)(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we construct and compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(sentence, outputs=logits)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we perpare the inputs and outputs to be fed to the model during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_train = df_train[\"Tweet\"].tolist()\n",
    "tweet_dev = df_dev[\"Tweet\"].tolist()\n",
    "X_train = embedder.embed_batch(tweet_train, max_sentence_len)\n",
    "Y_train = df_train[\"Intensity Score\"]\n",
    "X_dev = embedder.embed_batch(tweet_dev, max_sentence_len)\n",
    "Y_dev = df_dev[\"Intensity Score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we fit the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 9s 206ms/step - loss: 0.0704 - mae: 0.2091 - val_loss: 0.0434 - val_mae: 0.1758\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 5s 168ms/step - loss: 0.0253 - mae: 0.1245 - val_loss: 0.0349 - val_mae: 0.1442\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 5s 166ms/step - loss: 0.0197 - mae: 0.1118 - val_loss: 0.0336 - val_mae: 0.1476\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 5s 165ms/step - loss: 0.0164 - mae: 0.0970 - val_loss: 0.0305 - val_mae: 0.1331\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 5s 163ms/step - loss: 0.0100 - mae: 0.0761 - val_loss: 0.0300 - val_mae: 0.1325\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.0073 - mae: 0.0632 - val_loss: 0.0321 - val_mae: 0.1381\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 5s 154ms/step - loss: 0.0057 - mae: 0.0567 - val_loss: 0.0302 - val_mae: 0.1330\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 4s 145ms/step - loss: 0.0040 - mae: 0.0468 - val_loss: 0.0327 - val_mae: 0.1411\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 4s 148ms/step - loss: 0.0044 - mae: 0.0469 - val_loss: 0.0342 - val_mae: 0.1468\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 5s 157ms/step - loss: 0.0034 - mae: 0.0427 - val_loss: 0.0324 - val_mae: 0.1393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2b94a8a9b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          validation_data = (X_dev, Y_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the Pearson correlation coefficient for the development set as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6141037368772433, 1.1492500774076655e-15)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(Y_dev, model.predict(X_dev).reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perpare the features for each testset instance as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_test = df_test[\"Tweet\"].tolist()\n",
    "X_test = embedder.embed_batch(tweet_test, max_sentence_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we predict the labels for each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perpare the predictions as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame(data=predictions, columns=[\"prediction\"], index=df_test[\"ID\"])\n",
    "df_preds.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final step, we save the predictions as required by the competition guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./predictions/{}\".format(model_type)):\n",
    "    os.makedirs(\"./predictions/{}\".format(model_type), exist_ok=True)\n",
    "df_preds.to_csv(\"./predictions/{}/v_reg.tsv\".format(model_type), index=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
