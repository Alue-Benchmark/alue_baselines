{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMO/ARAVEC/FASTTEXT Baseline for Madar task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will walk you through the process of reproducing the ELMO/ARAVEC/FASTTEXT baseline for Madar task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Required Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the needed python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-27 22:30:41.855287: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-27 22:30:41.855303: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/cadmus/PycharmProjects/alue_baselines/env/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from embed_classer import embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pandas, we can load and inspect the training, validation, and testing datasets as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../../data/madar-1/MADAR-Corpus-26-train.tsv\", sep=\"\\t\", header=None, names=[\"Text\", \"label\"])\n",
    "df_dev = pd.read_csv(\"../../data/madar-1/MADAR-Corpus-26-dev.tsv\", sep=\"\\t\", header=None, names=[\"Text\", \"label\"])\n",
    "df_test = pd.read_csv(\"../../data/madar-1/MADAR-Corpus-26-test.tsv\", sep=\"\\t\", header=None, names=[\"Text\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we list the 5 first entries in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>هناك ، أمام بيانات السائح تماما .</td>\n",
       "      <td>MSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>لم اسمع بهذا العنوان من قبل بالقرب من هنا .</td>\n",
       "      <td>MSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>استمر في السير في هذا الطريق حتى تجد صيدلية .</td>\n",
       "      <td>MSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>كم تكلفة الإفطار ؟</td>\n",
       "      <td>MSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>كيف أستطيع مساعدتك ؟</td>\n",
       "      <td>MSA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Text label\n",
       "0              هناك ، أمام بيانات السائح تماما .   MSA\n",
       "1    لم اسمع بهذا العنوان من قبل بالقرب من هنا .   MSA\n",
       "2  استمر في السير في هذا الطريق حتى تجد صيدلية .   MSA\n",
       "3                             كم تكلفة الإفطار ؟   MSA\n",
       "4                           كيف أستطيع مساعدتك ؟   MSA"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we list the 5 first entries in the development data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>بالمناسبة ، اسمي هيروش إيجيما .</td>\n",
       "      <td>MSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>هذا القطار يتوقف في لاك فورست , أليس كذلك ؟</td>\n",
       "      <td>MSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>هذا الكارت , حسناً ؟</td>\n",
       "      <td>MSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>لم يخرج من الماكينة شيء .</td>\n",
       "      <td>MSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>عندك أية شيء يمكن أن أتعاطه للطفح الجلدي ؟</td>\n",
       "      <td>MSA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text label\n",
       "0              بالمناسبة ، اسمي هيروش إيجيما .   MSA\n",
       "1  هذا القطار يتوقف في لاك فورست , أليس كذلك ؟   MSA\n",
       "2                         هذا الكارت , حسناً ؟   MSA\n",
       "3                    لم يخرج من الماكينة شيء .   MSA\n",
       "4   عندك أية شيء يمكن أن أتعاطه للطفح الجلدي ؟   MSA"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we list the 5 first entries in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>لا أعرف كثيراً عن النبيذ ؟ ماذا يناسب هذا الطبق ؟</td>\n",
       "      <td>MSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>رايح عالمدرسة هون ؟</td>\n",
       "      <td>DAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قهوه مع كريمة و سكر ، لوسمحت .</td>\n",
       "      <td>SAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>بأي محطة لازم أنزل عشان أروح على امباير ستيت ب...</td>\n",
       "      <td>AMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اسمي ميتشيكو تاناكا ، ورقم الرحلة خمسة صفر واح...</td>\n",
       "      <td>JED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label\n",
       "0  لا أعرف كثيراً عن النبيذ ؟ ماذا يناسب هذا الطبق ؟   MSA\n",
       "1                                رايح عالمدرسة هون ؟   DAM\n",
       "2                     قهوه مع كريمة و سكر ، لوسمحت .   SAN\n",
       "3  بأي محطة لازم أنزل عشان أروح على امباير ستيت ب...   AMM\n",
       "4  اسمي ميتشيكو تاناكا ، ورقم الرحلة خمسة صفر واح...   JED"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by setting the randomisation seed and the maximum sentence length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(123)\n",
    "max_sentence_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"fasttext\"\n",
    "\n",
    "if model_type == \"aravec\":\n",
    "    model_path = '../pretrained/full_uni_sg_300_twitter.mdl'\n",
    "    size = 300\n",
    "elif model_type == \"fasttext\":\n",
    "    model_path = '../pretrained/cc.ar.300.bin'\n",
    "    size = 300\n",
    "elif model_type == \"elmo\":\n",
    "    model_path= '../pretrained'\n",
    "    size = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load our model of choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "embedder = embed(model_type, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the input and output to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = keras.Input(shape=(max_sentence_len, size), name='sentence')\n",
    "label = keras.Input(shape=(26,), name='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is followed by defining the structure of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-27 22:30:48.871687: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-08-27 22:30:48.871705: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-08-27 22:30:48.871719: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cadmus-ERAZER-P6605-MD61363): /proc/driver/nvidia/version does not exist\n",
      "2021-08-27 22:30:48.871872: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "forward_layer = tf.keras.layers.LSTM(size)\n",
    "backward_layer = tf.keras.layers.LSTM(size, go_backwards=True)\n",
    "masking_layer = tf.keras.layers.Masking()\n",
    "rnn = tf.keras.layers.Bidirectional(forward_layer, backward_layer=backward_layer)\n",
    "logits = rnn(sentence)\n",
    "logits = keras.layers.Dense(26, activation=tf.nn.softmax)(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we construct and compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(sentence, outputs=logits)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we perpare the inputs and outputs to be fed to the model during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(df_train[\"label\"])\n",
    "Y_train = le.transform(df_train[\"label\"])\n",
    "X_dev = embedder.embed_batch(df_dev[\"Text\"].tolist(), max_sentence_len)\n",
    "Y_dev = le.transform(df_dev[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the size of the input we need to constructor a generator as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, text, labels, max_sentence_len, batch_size=32, shuffle=True):\n",
    "        'Initialization'\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.text = text\n",
    "        self.shuffle = shuffle\n",
    "        self.max_sentence_len = max_sentence_len\n",
    "        self.list_IDs = list_IDs\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_text_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_text_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_text_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        for i in list_text_temp:\n",
    "            y.append(self.labels[i])\n",
    "            X.append(self.text[i])\n",
    "        return embedder.embed_batch(X, self.max_sentence_len), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we fit the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-27 22:30:49.972062: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1300/1300 [==============================] - 80s 60ms/step - loss: 2.1154 - accuracy: 0.3122 - val_loss: 1.7579 - val_accuracy: 0.4202\n",
      "Epoch 2/5\n",
      "1300/1300 [==============================] - 78s 60ms/step - loss: 1.6916 - accuracy: 0.4309 - val_loss: 1.6606 - val_accuracy: 0.4485\n",
      "Epoch 3/5\n",
      "1300/1300 [==============================] - 88s 68ms/step - loss: 1.5294 - accuracy: 0.4822 - val_loss: 1.5097 - val_accuracy: 0.4913\n",
      "Epoch 4/5\n",
      "1300/1300 [==============================] - 87s 67ms/step - loss: 1.4103 - accuracy: 0.5180 - val_loss: 1.4515 - val_accuracy: 0.5129\n",
      "Epoch 5/5\n",
      "1300/1300 [==============================] - 84s 65ms/step - loss: 1.3081 - accuracy: 0.5506 - val_loss: 1.4376 - val_accuracy: 0.5206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe87f88f2b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_generator = DataGenerator(df_train.reset_index()[\"index\"].tolist(), df_train['Text'].tolist(), Y_train, max_sentence_len)\n",
    "model.fit(training_generator, epochs=5, validation_data = (X_dev, Y_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perpare the features for each testset instance as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = embedder.embed_batch(df_test[\"Text\"].tolist(), max_sentence_len)\n",
    "Y_test = le.transform(df_test[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we predict the labels for each and evaluate the f1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5073711072964296"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict(X_test), 1)\n",
    "f1_score(Y_test, predictions, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perpare the predictions as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame(data=le.inverse_transform(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final step, we save the predictions as required by the competition guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./predictions/{}\".format(model_type)):\n",
    "    os.makedirs(\"./predictions/{}\".format(model_type), exist_ok=True)\n",
    "df_preds.to_csv(\"./predictions/{}/madar.tsv\".format(model_type), index=False, header=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
